{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer all questions and submit them either as an IPython notebook, LaTeX document, or Markdown document. Provide full answers for each question, including interpretation of the results. Each question is worth 25 points.\n",
    "\n",
    "This homework is due on Friday, December 8, 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "The `titanic.xls` spreadsheet in the `data` directory contains data regarding the passengers on the Titanic when it sank in 1912. A recent [Kaggle competition](http://www.kaggle.com/c/titanic-gettingStarted) was based on predicting survival for passengers based on the attributes in the passenger list. \n",
    "\n",
    "Use scikit-learn to build both a support vector classifier and a logistic regression model to predict survival on the Titanic. Use cross-validation to assess your models, and try to tune them to improve performance.\n",
    "\n",
    "Discuss the benefits and drawbacks of both approaches for application to such problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your work here\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ruiwang/source/BIOS_8366/data/titanic.xls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e4c9709dffe8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# for mac\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/Users/ruiwang/source/BIOS_8366/data/titanic.xls'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheetname, header, skiprows, skip_footer, index_col, names, parse_cols, parse_dates, date_parser, na_values, thousands, convert_float, has_index_names, converters, dtype, true_values, false_values, engine, squeeze, **kwds)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     return io._parse_excel(\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\myenv\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\myenv\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ruiwang/source/BIOS_8366/data/titanic.xls'"
     ]
    }
   ],
   "source": [
    "# for windows\n",
    "# file = 'C:/Users/Rui/source/BIOS_8366/data/titanic.xls'\n",
    "# for mac\n",
    "file = '/Users/ruiwang/source/BIOS_8366/data/titanic.xls'\n",
    "data = pd.read_excel(file)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the distribution of our interest: isbadbuy\n",
    "prop = data['survived'].value_counts()/len(data)\n",
    "print(prop)\n",
    "prop.plot(kind = 'pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in data:\n",
    "    data['initial']=data.name.str.extract('([A-Za-z]+)\\.') #lets extract the Salutations\n",
    "# replace intials with spelling error\n",
    "data['initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess',\n",
    "                         'Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],\n",
    "                        ['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other',\n",
    "                         'Other','Other','Mr','Mr','Mr','Mr'],inplace=True)\n",
    "data.groupby('initial')['age'].mean() #lets check the average age by Initials\n",
    "\n",
    "## Assigning the NaN Values with the Ceil values of the mean ages\n",
    "data.loc[(data.age.isnull())&(data.initial=='Mr'),'age']=33\n",
    "data.loc[(data.age.isnull())&(data.initial=='Mrs'),'age']=36\n",
    "data.loc[(data.age.isnull())&(data.initial=='Master'),'age']=5\n",
    "data.loc[(data.age.isnull())&(data.initial=='Miss'),'age']=22\n",
    "data.loc[(data.age.isnull())&(data.initial=='Other'),'age']=46\n",
    "\n",
    "# As we saw that maximum passengers boarded from Port S, we replace NaN with S.\n",
    "data['embarked'].fillna('S',inplace=True)\n",
    "data['age_band']=0\n",
    "data.loc[data['age']<=16,'age_band']=0\n",
    "data.loc[(data['age']>16)&(data['age']<=32),'age_band']=1\n",
    "data.loc[(data['age']>32)&(data['age']<=48),'age_band']=2\n",
    "data.loc[(data['age']>48)&(data['age']<=64),'age_band']=3\n",
    "data.loc[data['age']>64,'age_band']=4\n",
    "\n",
    "data['family_size']=0\n",
    "data['family_size']=data['parch']+data['sibsp'] #family size\n",
    "data['alone']=0\n",
    "data.loc[data.family_size==0,'alone']=1 #Alone\n",
    "\n",
    "#data['Fare_Range']=pd.qcut(data['fare'],4)\n",
    "#data.groupby(['Fare_Range'])['survived'].mean().to_frame().style.background_gradient(cmap='summer_r')\n",
    "\n",
    "data['fare_cat']=0\n",
    "data.loc[data['fare']<=7.91,'fare_cat']=0\n",
    "data.loc[(data['fare']>7.91)&(data['fare']<=14.454),'fare_cat']=1\n",
    "data.loc[(data['fare']>14.454)&(data['fare']<=31),'fare_cat']=2\n",
    "data.loc[(data['fare']>31)&(data['fare']<=513),'fare_cat']=3\n",
    "\n",
    "data['sex'].replace(['male','female'],[0,1],inplace=True)\n",
    "data['embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\n",
    "data['initial'].replace(['Mr','Mrs','Miss','Master','Other'], [0,1,2,3,4], inplace=True)\n",
    "data.drop(['name','ticket','cabin', 'age', 'fare', 'home.dest', 'boat', 'body'],axis=1,inplace=True)\n",
    "\n",
    "# rearrange the columns\n",
    "data = data[['survived', 'pclass', 'sex', 'sibsp', 'parch', 'embarked', \n",
    "             'initial', 'age_band', 'family_size', 'alone', 'fare_cat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':12})\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(10,10)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y = data['survived'].values\n",
    "X = data.drop(['survived'], axis = 1).values\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters={'kernel':['rbf','linear'],\n",
    "                  'C': np.logspace(-5, 5, 10),\n",
    "                  'gamma':np.logspace(-5, 5, 10)}\n",
    "\n",
    "scores = ['accuracy']\n",
    "\n",
    "clf = GridSearchCV(SVC(max_iter=1000, tol = 1e-6, random_state = 42), \n",
    "                   tuned_parameters, cv=5, n_jobs = -1,\n",
    "                  scoring='%s' % score)\n",
    "clf.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Best score set found on development set:\")\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(classification_report(y_true, y_pred))\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = np.array([\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters={'kernel':['rbf','linear'],\n",
    "                  'C': np.logspace(-5, 5, 10),\n",
    "                  'gamma':np.logspace(-5, 5, 10)}\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "clf = GridSearchCV(SVC(max_iter=1000, tol = 1e-6, random_state = 42), \n",
    "                   tuned_parameters, cv=5, n_jobs = -1,\n",
    "                  scoring='%s' % score)\n",
    "clf.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Best score set found on development set:\")\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(classification_report(y_true, y_pred))\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = np.array([\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regreesion Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = { 'C': np.logspace(-5, 10, 30),\n",
    "                   'penalty': ['l1', 'l2'],\n",
    "                   }\n",
    "\n",
    "scores = ['accuracy']\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(max_iter=1000, tol = 1e-6, random_state = 42), \n",
    "                   tuned_parameters, cv=5, n_jobs = -1,\n",
    "                  scoring='%s' % score)\n",
    "clf.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "labels = [0, 1]\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Best score set found on development set:\")\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = np.array([\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = { 'C': np.logspace(-5, 10, 30),\n",
    "                   'penalty': ['l1', 'l2'],\n",
    "                   }\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(max_iter=1000, tol = 1e-6, random_state = 42), \n",
    "                   tuned_parameters, cv=5, n_jobs = -1,\n",
    "                  scoring='%s' % score)\n",
    "clf.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "labels = [0, 1]\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Best score set found on development set:\")\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = np.array([\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the benefits and drawbacks of both approaches for application to such problems.\n",
    "\n",
    "a. Linear SVMs and logistic regression generally perform comparably in practice. Use SVM with a nonlinear kernel if you have reason to believe your data won't be linearly separable (or you need to be more robust to outliers than LR will normally tolerate). Otherwise, just try logistic regression first and see how you do with that simpler model. If logistic regression fails you, try an SVM with a non-linear kernel like a RBF. \n",
    "\n",
    "b. Set $p$ as number of features and $n$ as number of training examples. \n",
    "\n",
    "    1. If p >> n, apply logistic regression or linear SVMs.\n",
    "    2. If p is small and n is intermediate, use SVM with a nonlinear kernel.\n",
    "    3. If n >> p, create or add more features will help and then use logistics regression or linear SVMs.\n",
    "    \n",
    "c. Neural network likely to work well for most of these settings but might be slower to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "The file `TNNASHVI.txt` in your data directory contains daily temperature readings for Nashville, courtesy of the [Average Daily Temperature Archive](http://academic.udayton.edu/kissock/http/Weather/). This data, as one would expect, oscillates annually. Using PyMC3, use a Gaussian process to fit a non-parametric regression model to this data, choosing an appropriate covariance function. Plot 10 regression lines drawn from your process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "\n",
    "daily_temps = pd.read_table(\"../data/TNNASHVI.txt\", sep='\\s+', \n",
    "                            names=['month','day','year','temp'], na_values=-99)\n",
    "daily_temps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily temperature\n",
    "daily_temps.loc[daily_temps['year'] > 2010, 'temp'].plot(style='b.', figsize=(10,6), grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the temperature from 2011-2013\n",
    "df = daily_temps[daily_temps.year > 2010]\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection\n",
    "\n",
    "The temperature varies very periodically. From the plot above, there seems no trend of increasing or decreasing gradually anually. Therefore, I choose to use two parts to fit the data: one is the seasonal part and the other is noise part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "\n",
    "y = df.temp.values\n",
    "t = np.arange(len(df.temp)).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    # yearly periodic component x long term trend\n",
    "    ls = pm.HalfCauchy('ls', 1)\n",
    "    η = pm.HalfCauchy('η', 1)\n",
    "    \n",
    "    cov_seasonal = η**2 * pm.gp.cov.Periodic(1, period = 365, ls = ls)\n",
    "    gp_seasonal = pm.gp.Marginal(cov_func=cov_seasonal)\n",
    "    \n",
    "    # noise model\n",
    "    σ = pm.HalfCauchy(\"σ\", 1)\n",
    "    \n",
    "    y_ = gp_seasonal.marginal_likelihood(\"y\", X=t, y=y, noise=σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    start = pm.find_MAP(include_transformed=True)\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(1000, step=step, start=start)\n",
    "    pm.traceplot(trace, varnames=[\"η\", \"ls\", \"σ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    pred = gp_seasonal.conditional(\"temp_fit\", t)\n",
    "    samples = pm.sample_ppc(trace, vars=[pred], samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,5)); ax = fig.gca()\n",
    "\n",
    "plt.scatter(x=t, y=df.temp, c='b', s=50, label=\"observed data\")\n",
    "\n",
    "for x in samples['temp_fit']:\n",
    "    plt.plot(t, x, label = \"predicted data\")\n",
    "    \n",
    "plt.xlabel(\"days from 2011\"); plt.ylim([10,90]);\n",
    "plt.title(\"Nashville Daily Temperature\"); \n",
    "plt.legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Fit a series of random-forest classifiers to the Wisconsin breast cancer dataset (`wisconsin_breast_cancer.csv`), to explore the sensitivity to the parameters `max_features`, the number of variables considered for splitting at each step, `max_depth`, the maximum depth of the tree, and `n_estimators`, the number of trees in the forest. Use apprpriate metrics of performance, and include plots against a suitably-chosen range of values for these parameters.\n",
    "\n",
    "Dataset description: Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "- `radius` (mean of distances from center to points on the perimeter) \n",
    "- `texture` (standard deviation of gray-scale values) \n",
    "- `perimeter` \n",
    "- `area` \n",
    "- `smoothness` (local variation in radius lengths) \n",
    "- `compactness` (perimeter^2 / area - 1.0) \n",
    "- `concavity` (severity of concave portions of the contour) \n",
    "- `concave points` (number of concave portions of the contour) \n",
    "- `symmetry` \n",
    "- `fractal dimension` (\"coastline approximation\" - 1)\n",
    "\n",
    "The outcome to be predicted is tumor type (M = malignant, B = benign)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your work here\n",
    "file = '/Users/ruiwang/source/BIOS_8366/data/wisconsin_breast_cancer.csv'\n",
    "df = pd.read_csv(file)\n",
    "df['diagnosis'].replace(['M','B'],[0,1],inplace=True)\n",
    "df.drop(['id'], axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the distribution of our interest: isbadbuy\n",
    "prop = df['diagnosis'].value_counts()/len(df)\n",
    "print(prop)\n",
    "prop.plot(kind = 'pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above pie figure, the target we predict is almost a balanced dataset (63% vs 37%). Our prediction target is whether the breast cancer is malignant (1) or benign (0). For these similar problems, the analysis is sensitive to the false negative, which can be translated by several metrics like precision ($\\frac {tp}{tp+fn}$), accuracy ($\\frac {tn + tp} {tn + tp + fn + fp}$) or f1 score ($2*\\frac {recall*precision}{recall + precision}$).\n",
    "\n",
    "For classification, it is better to plot the confusion matrix or precision-recall curve (ROC curve)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use recall as scoring to do parameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "y = df['diagnosis'].values\n",
    "X = df.drop(['diagnosis'], axis = 1).values\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "tuned_parameters = {\"n_estimators\": [10, 20, 50, 100, 500], \n",
    "                    \"max_depth\": [3, 5, 10, 20], \n",
    "                    \"max_features\": [1, 3, 5, 10]\n",
    "                    }\n",
    "\n",
    "scores = ['recall']\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), \n",
    "                   tuned_parameters,\n",
    "                   cv=5, n_jobs = -1, scoring='%s' % score)\n",
    "clf.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "labels = [0, 1]\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Best score set found on development set:\")\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = np.array([\"0\", \"1\"]))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use accuracy as scoring to do parameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "tuned_parameters = {\"n_estimators\": [10, 20, 50, 100, 500], \n",
    "                    \"max_depth\": [3, 5, 10, 20], \n",
    "                    \"max_features\": [1, 3, 5, 10]\n",
    "                    }\n",
    "\n",
    "scores = ['accuracy']\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), \n",
    "                   tuned_parameters,\n",
    "                   cv=5, n_jobs = -1, scoring='%s' % score)\n",
    "clf.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "labels = [0, 1]\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Best score set found on development set:\")\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = np.array([\"0\", \"1\"]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use f1 score as scoring to do parameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "tuned_parameters = {\"n_estimators\": [10, 20, 50, 100, 500], \n",
    "                    \"max_depth\": [3, 5, 10, 20], \n",
    "                    \"max_features\": [1, 3, 5, 10]\n",
    "                    }\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), \n",
    "                   tuned_parameters,\n",
    "                   cv=5, n_jobs = -1, scoring='%s' % score)\n",
    "clf.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "labels = [0, 1]\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Best score set found on development set:\")\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = np.array([\"0\", \"1\"]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Use a grid search to optimize the number of estimators and max_depth for a Gradient Boosted Decision tree using the Wisconsin breast cancer data. Plug this optimal ``max_depth`` into a *single* decision tree.  Does this single tree over-fit or under-fit the data? Repeat this for the Random Forest.  Construct a single decision tree using the ``max_depth`` which is optimal for the Random Forest.  Does this single tree over-fit or under-fit the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For parameters optimization in grid search, I choose to apply recall metric as scoring since it is most sensitive for patient features in cancer research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your work here\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "tuned_parameters = {\"n_estimators\": [10, 20, 50, 100, 200, 300, 500, 1000], \n",
    "                    \"max_depth\": [3, 5, 10, 15, 20, 50] \n",
    "                    }\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), \n",
    "                   tuned_parameters,\n",
    "                   cv=5, n_jobs = -1, scoring='recall')\n",
    "clf.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "labels = [0, 1]\n",
    "\n",
    "print(\"Optimize based on %s metric\" % score)\n",
    "print()\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Best score set found on development set:\")\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = np.array([\"0\", \"1\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check overfit or underfit\n",
    "clf1 = GradientBoostingClassifier(n_estimators = 1, max_depth = 3)\n",
    "clf1.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "labels = [0, 1]\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = np.array([\"0\", \"1\"])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above confusion matrix, we can conclude a single decision tree does not overfit for test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "tuned_parameters = {\"n_estimators\": [10, 20, 50, 100, 200, 300, 500, 1000], \n",
    "                    \"max_depth\": [3, 5, 10, 15, 20, 50] \n",
    "                    }\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), \n",
    "                   tuned_parameters,\n",
    "                   cv=5, n_jobs = -1, scoring='recall')\n",
    "clf.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "labels = [0, 1]\n",
    "\n",
    "print(\"Optimize based on %s metric\" % score)\n",
    "print()\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Best score set found on development set:\")\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = np.array([\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check overfit or underfit\n",
    "clf1 = RandomForestClassifier(n_estimators = 1, max_depth = 5)\n",
    "clf1.fit(X_train, y_train)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "labels = [0, 1]\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), classes = np.array([\"0\", \"1\"])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above confusion matrix, we can conclude a single tree using Random Forest does not overfit for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
