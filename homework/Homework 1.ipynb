{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer all questions and submit them either as an IPython notebook, LaTeX document, or Markdown document. Each question is worth 25 points.\n",
    "\n",
    "This homework is due Friday, September 22, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "The data below provides counts of a flour beetle (Tribolium confusum) population at various points in time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 0,8,28,41,63,79,97,117,135,154\n",
    "beetles = 2,47,192,256,768,896,1120,896,1184,1024\n",
    "\n",
    "plt.plot(days, beetles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An elementary model for population growth is the logistic model:\n",
    "\n",
    "$$\\frac{dN}{dt} = rN\\left(1 - \\frac{N}{K}\\right)$$\n",
    "\n",
    "where $N$ is population size, $t$ is time, $r$ is a growth rate parameter, and $K$ is a parameter that represents the population carrying capacity of the environment. The solution to this differential equation is given by: \n",
    "\n",
    "$$N_t = f(t) = \\frac{KN_0}{N_0 + (K - N_0)\\exp(-rt)}$$\n",
    "\n",
    "where $N_t$ denotes the population size at time $t$. \n",
    "\n",
    "1. Fit the logistic growth model to the flour beetle data using optimization to minimize the sum of squared errors between model predictions and observed counts.\n",
    "\n",
    "2. In many population modeling applications, an assumption of lognormality is adopted. The simplest assumption would be that the $\\log(N_t)$ are independent and normally distributed with mean $\\log[f(t)]$ and variance $\\sigma^2$. Find the MLEs under this assumption, and provide estimates of standard errors and correlation between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Question 1.1\n",
    "We can rewrite the logistic model to:\n",
    "\n",
    "$$\\frac{d(log\\frac{p}{1-p})}{dt} = r, \\text{where } p = \\frac{N}{K}$$\n",
    "\n",
    "So we can $logistic(p)=rt+logistic(p_0), p = \\frac{N}{K} \\text{and } p_0 = \\frac{N_0}{K}$. Finally the solution comes as:\n",
    "\n",
    "$$N_t = f(t) = \\frac{KN_0}{N_0 + (K - N_0)\\exp(-rt)}$$\n",
    "\n",
    "Fit the logistic growth model to the flour beetle data using optimization to minimize the sum of squared errors between model predictions and observed counts.\n",
    "\n",
    "The cost function $J$ can be expressed as:\n",
    "$$J = \\frac{1}{2m} (\\hat{N_t} - N_t)^2 \\sim (\\hat{N_t} - N_t)^2$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for question 1.1\n",
    "def costfunc(theta):\n",
    "    K = theta[0]\n",
    "    r = theta[1]\n",
    "    N_0 = 2\n",
    "    t = days\n",
    "    N_t = beetles\n",
    "    N_t_hat = 1.0*N_0*K/(N_0+(K-N_0)*np.exp(-r*t))\n",
    "    return np.sum((N_t_hat - N_t)**2)\n",
    "\n",
    "days = np.array(days)\n",
    "beetles = np.array(beetles)\n",
    "# optimization\n",
    "from scipy.optimize import minimize\n",
    "# intialized guess\n",
    "\n",
    "theta = [500, 0.5]\n",
    "res = minimize(costfunc, theta, method='Nelder-Mead', tol = 1e-6)\n",
    "K = res.x[0]\n",
    "r = res.x[1]\n",
    "print(\"The first model using least square error gives K = %.3f, r = %.3f\" % (K, r))\n",
    "N_0 = 2\n",
    "model1 = 1.0*N_0*K/(N_0+(K-N_0)*np.exp(-r*days))\n",
    "\n",
    "# plot vs the original\n",
    "plt.plot(days, beetles, c = 'b')\n",
    "plt.plot(days, model1, c = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1.2 The assumptions:\n",
    "\n",
    "$$ log(N_t) \\sim N(f(t), \\sigma^2)$$\n",
    "Get the log-likelihood for each data point based on the normal model and add them up to minimize. Since we need to provide estimates of standard errors and correlation between them, let's bootstrap the 10-point dataset for 1000 times and obtain $K_i$ and $r_i$ in each loop. Finally, calculate each strandard error and their correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for question 1.2\n",
    "from scipy.stats import norm\n",
    "\n",
    "def loglikelihood(theta):\n",
    "    K = theta[0]\n",
    "    r = theta[1]\n",
    "    var = theta[2]\n",
    "    t = new_days\n",
    "    x = new_beetles\n",
    "    N_0 = 2\n",
    "    # will use minimize, multiply by -1 instead\n",
    "    return -1.0*np.sum(norm.logpdf(np.log(x),loc=np.log(1.0*N_0*K/(N_0+(K-N_0)*np.exp(-r*t))),scale=var))\n",
    "\n",
    "# intialize at each loop\n",
    "n = 1000\n",
    "K_para = np.zeros(n)\n",
    "r_para = np.zeros(n)\n",
    "var_para = np.zeros(n)\n",
    "new_days = np.zeros(days.shape)\n",
    "new_beetles = np.zeros(beetles.shape)\n",
    "\n",
    "for i in range(n):\n",
    "    index = np.random.choice(len(days), len(days))\n",
    "    new_days = np.take(days, index)\n",
    "    new_beetles = np.take(beetles, index)\n",
    "    theta = [500, 0.5, np.var(np.log(new_beetles))]\n",
    "    res = minimize(loglikelihood, theta, method='Nelder-Mead', tol = 1e-6)\n",
    "    K_para[i] = res.x[0]\n",
    "    r_para[i] = res.x[1]\n",
    "    var_para[i] = res.x[2]\n",
    "\n",
    "print(\"The standard error of K is %.3f.\" % np.var(K_para))\n",
    "print(\"The standard error of r is %.3f.\" % np.var(r_para))\n",
    "print(\"The standard error of var is %.3f.\" % np.var(var_para))\n",
    "print(\"The correlation between K and r is %.3f.\" % np.corrcoef(K_para, r_para)[0,1])\n",
    "print(\"The correlation between r and var is %.3f.\" % np.corrcoef(r_para, var_para)[0,1])\n",
    "print(\"The correlation between var and K is %.3f.\" % np.corrcoef(var_para, K_para)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "A. Implement simulated annealing for minimizing the AIC for the baseball salary regression problem. Model your algorithm on the example given in class. \n",
    "1. Compare the effects of different cooling schedules (different temperatures and different durations at each temperature).  \n",
    "2. Compare the effect of a proposal distribution that is discrete uniform over 2-neighborhoods versus one that is discrete uniform over 3-neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseball = pd.read_table('../data/baseball.dat', sep='\\s+')\n",
    "predictors = baseball.copy()\n",
    "logsalary = predictors.pop('salary').apply(np.log)\n",
    "nrows, ncols = predictors.shape\n",
    "\n",
    "aic = lambda g, X, y: len(y) * np.log(sum((g.predict(X) - y)**2)/len(y)) + 2*g.rank_\n",
    "\n",
    "def annealingfunc(cooling_schedule, neighbors= 1, color = 'r'):\n",
    "    aic_values = []\n",
    "    solution_current = solution_best = np.random.binomial(1, 0.5, ncols).astype(bool)\n",
    "    solution_vars = predictors[predictors.columns[solution_current]]\n",
    "    g = LinearRegression().fit(X=solution_vars, y=logsalary)\n",
    "    aic_best = aic(g, solution_vars, logsalary)\n",
    "    aic_values.append(aic_best)\n",
    "    for tau in cooling_schedule:\n",
    "\n",
    "        # Random change # 0f neighborhood\n",
    "        flips = np.random.choice(ncols, neighbors, replace = False)\n",
    "        for flip in flips:\n",
    "            solution_current[flip] = not solution_current[flip] \n",
    "        solution_vars = predictors[predictors.columns[solution_current]]\n",
    "        g = LinearRegression().fit(X=solution_vars, y=logsalary)\n",
    "        aic_step = aic(g, solution_vars, logsalary)\n",
    "        alpha = min(1, np.exp((aic_values[-1] - aic_step)/tau))\n",
    "\n",
    "        if ((aic_step < aic_values[-1]) or (np.random.uniform() < alpha)):\n",
    "            # Accept proposed solution\n",
    "            aic_values.append(aic_step)\n",
    "            if aic_step < aic_best:\n",
    "                # Replace previous best with this one\n",
    "                aic_best = aic_step\n",
    "                solution_best = solution_current.copy()\n",
    "        else:\n",
    "            # Revert solution\n",
    "            solution_current[flip] = not solution_current[flip]\n",
    "            aic_values.append(aic_values[-1])\n",
    "    # for comparison, add color argument\n",
    "    plt.plot(aic_values, color)\n",
    "    plt.xlim(0, len(aic_values))\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('AIC')\n",
    "    print('Best AIC: {0}\\nBest solution: {1}\\nDiscovered at iteration {2}'.format(aic_best, \n",
    "                np.where(solution_best==True),\n",
    "                np.where(aic_values==aic_best)[0][0]))\n",
    "    plt.plot(np.where(aic_values==aic_best)[0][0], aic_best, color + 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the effects of different cooling schedules (different temperatures and different durations at each temperature).\n",
    "tau_start = 10\n",
    "# in class cases\n",
    "cooling_schedule = [tau_start]*60 + [tau_start/2]*120 + [tau_start/10]*180\n",
    "annealingfunc(cooling_schedule, color = 'b')\n",
    "# flip the sequence\n",
    "annealingfunc(cooling_schedule[::-1], color = 'g')\n",
    "# try equal length\n",
    "cooling_schedule = [tau_start]*120 + [tau_start/2]*120 + [tau_start/10]*120\n",
    "annealingfunc(cooling_schedule, color = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flipping the cooling schedule make the AIC values increase in last few iterations. So starting with high-value temperature is crucial. Probably choose smaller values as the iteration goes on. I prefer the original cooling schedule in our example case (blue curve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try different ratio factors 0.9, 0.5, 0.1\n",
    "cooling_schedule = [tau_start*0.9**i for i in range(360)]\n",
    "annealingfunc(cooling_schedule, color = 'c')\n",
    "cooling_schedule = [tau_start*0.5**i for i in range(360)]\n",
    "annealingfunc(cooling_schedule, color = 'y')\n",
    "cooling_schedule = [tau_start*0.1**i for i in range(360)]\n",
    "annealingfunc(cooling_schedule, color = 'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we obtain the best and minimum AIC value for 0.9 and 0.5 ratio factor earlier than 0.1. I pefer use 0.9 or 0.8 because it makes the cooling schedule more smoothly than 0.5 and 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the effect of a proposal distribution that is discrete uniform \n",
    "# over 2-neighborhoods versus one that is discrete uniform over 3-neighborhoods.\n",
    "cooling_schedule = [tau_start*i/360 for i in range(360, 0, -1)]\n",
    "annealingfunc(cooling_schedule, neighbors =2, color = 'b')\n",
    "annealingfunc(cooling_schedule, neighbors =3, color = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing 3-neighborhoods seems better than 2-neighborhoods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Implement a genetic algorithm for minimizing the AIC for the baseball salary regression problem. Model your algorithm on Example 3.5. \n",
    "1. Compare the effects of using different mutation rates.  \n",
    "2. Compare the effects of using different generation sizes.  \n",
    "3. Instead of the selection mechanism used in the class example, try using independent selection of both parents with probabilities proportional to their fitness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_fitness(aic_values):\n",
    "    P = len(aic_values)\n",
    "    aic_rank = (-aic_values).argsort().argsort()+1.\n",
    "    return 2.*aic_rank/(P*(P+1.))\n",
    "\n",
    "def geneticfunc(mutation_rate, pop_size, iterations, double_selection = False, color = 'b'):\n",
    "    aic_best = []\n",
    "    best_solution = []\n",
    "    aic_history = []\n",
    "    # Initialize genotype\n",
    "    current_gen = np.random.binomial(1, 0.5, pop_size*ncols).reshape((pop_size, ncols))\n",
    "    for i in range(iterations):\n",
    "\n",
    "        # Get phenotype\n",
    "        current_phe = [predictors[predictors.columns[g.astype(bool)]] for g in current_gen]\n",
    "        # Calculate AIC\n",
    "        current_aic = np.array([aic(LinearRegression().fit(X=x, y=logsalary), x, logsalary) for x in current_phe])\n",
    "        # Get lowest AIC\n",
    "        aic_best.append(current_aic[np.argmin(current_aic)])\n",
    "        best_solution.append(current_gen[np.argmin(current_aic)])\n",
    "\n",
    "        # Calculate fitness according to AIC rank\n",
    "        fitness = calculate_fitness(current_aic)\n",
    "\n",
    "        # Choose first parents according to fitness\n",
    "        moms = np.random.choice(range(pop_size), size=int(pop_size/2), p=fitness)\n",
    "        if not double_selection:\n",
    "            # Choose second parents randomly\n",
    "            # in the example\n",
    "            dads = np.random.choice(range(pop_size), size=int(pop_size/2))\n",
    "        else:\n",
    "            # Choose second parents according to fitness\n",
    "            dads = np.random.choice(range(pop_size), size=int(pop_size/2), p=fitness)\n",
    "\n",
    "        next_gen = []\n",
    "        for x,y in zip(current_gen[moms], current_gen[dads]):\n",
    "            # Crossover\n",
    "            cross = np.random.randint(0, ncols)\n",
    "            child1 = np.r_[x[:cross], y[cross:]]\n",
    "            child2 = np.r_[y[:cross], x[cross:]]\n",
    "            # Mutate\n",
    "            m1 = np.random.binomial(1, mutation_rate, size=ncols).astype(bool)\n",
    "            child1[m1] = abs(child1[m1]-1)\n",
    "            m2 = np.random.binomial(1, mutation_rate, size=ncols)\n",
    "            child2[m2] = abs(child1[m2]-1)\n",
    "            next_gen += [child1, child2]\n",
    "\n",
    "        # Increment generation\n",
    "        current_gen = np.array(next_gen)\n",
    "        # Store AIC values\n",
    "        aic_history.append(current_aic)\n",
    "    \n",
    "    plt.plot(aic_best, color)\n",
    "    plt.xlim(0, iterations)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('AIC')\n",
    "    print(\"The best and minimum AIC is \" +str(min(aic_best)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the effects of using different mutation rates.\n",
    "mutation_rates = [0.2, 0.1, 0.05, 0.02, 0.005]\n",
    "colors = ['b', 'g', 'r', 'c', 'y']\n",
    "for i in range(len(colors)):\n",
    "    geneticfunc(mutation_rates[i], pop_size = 20, iterations = 200, color = colors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that 0.02 is better than other mutation_rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the effects of using different generation sizes.\n",
    "generation_sizes = [10, 20, 30, 40, 50]\n",
    "colors = ['b', 'g', 'r', 'c', 'y']\n",
    "for i in range(len(colors)):\n",
    "    geneticfunc(mutation_rate = 0.02, pop_size = 20, iterations = 200, color = colors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the generation size grows (for example, 50), we obtained the best and minimum AIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instead of the selection mechanism used in the class example, \n",
    "# try using independent selection of both parents with probabilities proportional to their fitness.\n",
    "geneticfunc(mutation_rate = 0.02, pop_size = 20, iterations = 200, double_selection = False, color = 'b')\n",
    "geneticfunc(mutation_rate = 0.02, pop_size = 20, iterations = 200, double_selection = True, color = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 0.02 as mutation rate, 20 as generation size. The blue curve represents our original case in the example while we choose both parents according to the fitness and show the AIC tendency in the red curve. Without comparing the AIC values (very close), the blue curve seems more gradually decreasing to the minimum while the red curve is fast dropping down. Maybe I will prefer the blue curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Use the combinatorial optimization method of your choice to obtain a solution to the traveling salesman problem for the Brazilian cities described in the lecture notes, using minimum total distance as the criterion. Use the the first city listed in the dataset as \"home\" (*i.e.* the trip must start and end there). I will award 5 bonus points to the best solution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rui\\AppData\\Local\\conda\\conda\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:39: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133.474010118\n",
      "[10 12 15 20 17 16 13 18 21 22 23 25 24 19 14 11  9  8  7  5  6  3  2  1  0\n",
      "  4]\n"
     ]
    }
   ],
   "source": [
    "def parse_latlon(x):\n",
    "    d, m, s = map(float, x.split(':'))\n",
    "    ms = m/60. + s/3600.\n",
    "    if d<0:\n",
    "        return d - ms\n",
    "    return d + ms\n",
    "\n",
    "cities =  pd.read_csv('../data/brasil_capitals.txt', \\\n",
    "                      names=['city','lat','lon'])[['lat','lon']].applymap(parse_latlon)\n",
    "cities = np.array(cities)\n",
    "\n",
    "def distance(route):\n",
    "    '''\n",
    "    route is a non-replace index of cities.\n",
    "    its sequence represents the traveling salesman route.\n",
    "    return: distance, route\n",
    "    '''\n",
    "    loop = None \n",
    "    loop = np.append(route, route[0])\n",
    "    res = 0\n",
    "    for i in range(len(loop)-1):\n",
    "        res += np.sqrt((cities[loop[i+1]][0] - cities[loop[i]][0])**2 + (cities[loop[i+1]][1] - cities[loop[i]][1])**2)\n",
    "    return res\n",
    "\n",
    "def annealingfunc(route, cooling_schedule, iteration_schedule, neighbors = 3):\n",
    "    cur_distance = distance(route)\n",
    "    # the simulating annealing run\n",
    "    for cooling_step in range(len(cooling_schedule)):\n",
    "        for iteration in range(iteration_schedule[cooling_step]):\n",
    "            # random change # of index\n",
    "            new_route = route.copy()\n",
    "            # index in the original route\n",
    "            flip_index = np.random.choice(len(route), size = neighbors, replace = False)\n",
    "            # index in the new route, use the permutation of flip_index\n",
    "            new_index = np.random.permutation(flip_index)\n",
    "            for i, j in zip(new_index, flip_index):\n",
    "                new_route[i] = route[j]\n",
    "            new_distance = distance(new_route)\n",
    "            # find alpha\n",
    "            alpha = min(1, np.exp((cur_distance-new_distance)/cooling_schedule[cooling_step]) )\n",
    "            # Accept or Reject?\n",
    "            if (new_distance < cur_distance) or (np.random.uniform() < alpha):\n",
    "                route = new_route\n",
    "                cur_distance = new_distance\n",
    "#     print(\"Distance:{0: .3f}, Route:{1}\".format(cur_distance, route))\n",
    "    return cur_distance, route \n",
    "\n",
    "# try different hyperparameters\n",
    "tau_start_list = [10, 20, 30]\n",
    "steps_list = [30, 50, 100]\n",
    "factor_list = [0.9, 0.8, 0.7]\n",
    "neighbors_list = [2,4,6]\n",
    "distance_list = []\n",
    "route_list = []\n",
    "\n",
    "for tau_start in tau_start_list:\n",
    "    for steps in steps_list:\n",
    "        for factor in factor_list:\n",
    "            for neighbors in neighbors_list:\n",
    "                # initialize\n",
    "                    cooling_schedule = [tau_start*factor**i for i in range(steps)]\n",
    "                    iteration_schedule = [10]*int(steps/5) + [20]*int(steps/5) + [50]*int(steps/5) \\\n",
    "                    + [100]*int(steps/5) + [300]*int(steps/5)\n",
    "                    route = np.random.permutation(range(len(cities)))\n",
    "                    temp_distance = None\n",
    "                    temp_route = None\n",
    "                    temp_distance, temp_route = annealingfunc(route, cooling_schedule, iteration_schedule, neighbors = neighbors)   \n",
    "                    distance_list.append(temp_distance)\n",
    "                    route_list.append(temp_route)\n",
    "\n",
    "# get the index of the smallest value in running results\n",
    "ind = distance_list.index(min(distance_list))\n",
    "print(distance_list[ind])\n",
    "print(route_list[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.285\n",
      "[0, 1, 2, 3, 6, 5, 7, 8, 9, 11, 14, 19, 18, 21, 22, 23, 24, 25, 20, 17, 16, 13, 15, 12, 10, 4]\n"
     ]
    }
   ],
   "source": [
    "# This chunk is used for saving best-so-far results.\n",
    "# format, put 0 first\n",
    "best_route = [ 6 , 5,  7,  8,  9, 11, 14, 19, 18, 21, 22, 23, 24, 25, 20, 17, 16, 13, 15, 12, 10,  4,  0,  1,  2, 3]\n",
    "zero_index = best_route.index(0)\n",
    "best_route = best_route[zero_index:] + best_route[:zero_index]\n",
    "best_distance = distance(best_route)\n",
    "print(\"%.3f\"%best_distance)\n",
    "print(best_route)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suppose the genetic algorithm should have better results than the stimulating annealing method. There are a lot of papers discussing it. Here I found a paper: Genetic algorithms for the traveling salesman problem by Jean-Yves Potvin, Annals of Operations Research. There are a lot of crossover operators when passing the gene from parents to the childs. I am not quite sure how to define the fitness in this question. I would like to see the code using the genetic algorithm after grading. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "The `../data/ebola` folder contains summarized reports of Ebola cases from three countries during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "From these data files, use `pandas` to import them and create a single data frame that includes the daily totals of new cases and deaths for each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# three paths\n",
    "path1 =r'/Users/ruiwang/source/bios_8366/data/ebola/guinea_data'\n",
    "path2 =r'/Users/ruiwang/source/bios_8366/data/ebola/liberia_data'\n",
    "path3 =r'/Users/ruiwang/source/bios_8366/data/ebola/sl_data'\n",
    "\n",
    "# add up\n",
    "allFiles = []\n",
    "for path in [path1, path2, path3]:\n",
    "    allFiles += glob.glob(path + \"/*.csv\")\n",
    "\n",
    "ebola = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "\n",
    "ebola = pd.concat(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rearrange the columns\n",
    "col = ebola.columns.tolist()\n",
    "for x in ['Date', 'Description', 'Totals']:\n",
    "    col.remove(x)\n",
    "col = ['Date', 'Description', 'Totals'] + col\n",
    "ebola = ebola[col].fillna(0)\n",
    "ebola = ebola[(ebola['Description'] == 'New cases of confirmed') & (ebola['Description'] == 'New deaths registered today')]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
